{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scientist Position Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Machine Learning Pipeline\n",
    "\n",
    "> 1) The goal.\n",
    "\n",
    "> 2) Fetch the data.\n",
    "\n",
    "> 3) Gain insights from data also perform data sanity check.\n",
    "\n",
    "> 4) Preprocess the data.\n",
    "\n",
    "> 5) Explore different algorithms.\n",
    "\n",
    "> 6) Short list best ones.\n",
    "\n",
    "> 7) Combine them into a great solution.\n",
    "\n",
    "> 8) Present your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOAL:-\n",
    "\n",
    "> Build a supervised classifier for the MNIST dataset that achieves a high accuracy (over 95% is easily achievable) on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal Takeaways:-\n",
    "\n",
    "1) Build a supervised classifier.\n",
    "\n",
    "2) Get an accuracy above 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change data_home to wherever to where you want to download your data\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label', 'data']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.COL_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mnist has both label and data which makes it a supervised learning algorithm. Also the data isn't linearly separable and the data is categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mldata.org dataset: mnist-original'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=mnist.data\n",
    "targets=mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.concat([pd.DataFrame(data),pd.DataFrame(targets)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(targets, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s=dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=list(s.keys())\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6903, 7877, 6990, 7141, 6824, 6313, 6876, 7293, 6825, 6958]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=list(s.values())\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the data is Imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6903., 7877., 6990., 7141., 6824., 6313., 6876., 7293., 6825.,\n",
       "        6958.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIEmdMgAkqVP/H1TQsyzqoMZZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25b96a62a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(m,weights=l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Function to normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From the above graph we see that the data is not imbalanced. But it has to be normalized, because:\n",
    "\n",
    "> 1)Several algorithms, in particular SVM, can sometimes converge far faster on normalized data.\n",
    "\n",
    "> 2)When the model is sensitive to magnitude, and the units of two different features are different, and arbitrary. Normalization has to be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Function to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(a):\n",
    "    max_input=np.max(a)\n",
    "    min_input=np.min(a)\n",
    "    return (a-min_input)/(max_input-min_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset to training, testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    normalize(mnist.data), mnist.target, test_size=10000, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape of training, validation, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set:  (50000, 784)\n",
      "Shape of test set:  (10000, 784)\n",
      "Shape of validation set:  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training set: \", X_train.shape)\n",
    "print(\"Shape of test set: \", X_test.shape)\n",
    "print(\"Shape of validation set: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTINOMIAL LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# all parameters not specified are set to their defaults\n",
    "# default solver is incredibly slow thats I changed it\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs',C=0.5,max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score/Accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.917\n"
     ]
    }
   ],
   "source": [
    "score = logisticRegr.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Choice of 'n': </b>\n",
    "\n",
    "In a paper I recently read https://dl.acm.org/citation.cfm?id=1643047 as Kohavi cited,\n",
    "\n",
    "> If the training set is small, it is better to use a larger 'n'. This simulates having a larger training set. The choice of k involves a tradeoff between efficiency and the accuracy of the error prediction. More folds reduce the bias of the estimate of the generalization error, but they take more time to compute. Since the training set is large, a small value of 'n' is choosen.\n",
    "\n",
    "> More training samples usually means that we are at a flatter part of the learning curve, so the difference between the surrogate models and the \"real\" model trained on all 'n' samples becomes negligible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How I choosed the value of 'n' and why?\n",
    "\n",
    "In order to lower the variance of the CV result, I repeat/iterate the CV with new random splits. I tend to think mainly of the total number of models calculated (in analogy to bootstrapping). So I decided to go for 100 x 10-fold CV or 200 x 5-fold CV. I found the variance when cv=10 to be low so I opted the value 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score=cross_val_score(logisticRegr,X_train,y_train,cv=10,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:  [0.91625025 0.91505097 0.91405157 0.91505097 0.92021596 0.915\n",
      " 0.91695017 0.91735041 0.91254753 0.91653323]\n",
      "mean 0.9159001050000576\n",
      "std 0.001981543562374655\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracies: \",score)\n",
    "\n",
    "print(\"mean\",score.mean())\n",
    "print(\"std\",score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Deep Learning book by Ian Goodfellow, Algorithm A is better than algorithm B if upper bound of 95% CI for error of algorithm A is less than lower bound 95% CI for error of algorithm B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the 95% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mean=score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8792641008000553"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean-1.96*mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7110643108001704"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean+1.96*mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001981543562374655"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Classifiers used:\n",
    "> - RandomForestClassifier\n",
    "- ExtraTreesClassifier\n",
    "- MLPClassifier\n",
    "- LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_forest_clf = RandomForestClassifier(random_state=42,n_estimators=20)\n",
    "extra_trees_clf = ExtraTreesClassifier(random_state=42,n_estimators=20,max_features='sqrt')\n",
    "svm_clf = LinearSVC(random_state=42,dual=False)\n",
    "mlp_clf = MLPClassifier(random_state=42,max_iter=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training various Classifiers with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "Training the ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "Training the LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0)\n",
      "Training the MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "Training the LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "estimators = [random_forest_clf, extra_trees_clf, svm_clf, mlp_clf,logisticRegr]\n",
    "for estimator in estimators:\n",
    "    print(\"Training the\", estimator)\n",
    "    estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracies for all the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9606, 0.9646, 0.913, 0.9783, 0.9157]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_val, y_val) for estimator in estimators]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above the best accuracy is found to be the MLP Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Why are RandomForestClassifier, ExtraTreesClassifier, MLPClassifier better than Logistic and SVM?</b>\n",
    "\n",
    "> RandomForest vs Logistic Regression:\n",
    "\n",
    "    Can handle large feature space\n",
    "    Can handle non-linear feature interactions\n",
    "    Do not rely on entire data\n",
    "    \n",
    "> ExtraTreesClassifier vs Logistic Regression:\n",
    "\n",
    "    ETs are generally cheaper to train from a computational point of view but can grow much bigger. \n",
    "    ETs can sometime generalize better than RandomForests. Which inturn makes it better when compared to Logistic.\n",
    "\n",
    "> Multi layer perceptron outperform other methods because there is really a lot of data and their structure is complex because they have many layers. In particular, if we want to solve a classification problem, we need a lot of examples per class.\n",
    "\n",
    "\n",
    "> SVM tries to maximize the margin between the closest support vectors while Logistic the posterior class probability. Thus, SVM find a solution which is as fare as possible for the two categories while LR has not this property. SVMs are also not sensitive to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Voting Classifier works?\n",
    "\n",
    "Let's take a simple example to illustrate how both approaches work.\n",
    "\n",
    "Imagine that you have 3 classifiers (1, 2, 3) and two classes (A, B), and after training you are predicting the class of a single point.\n",
    "\n",
    "<b>Hard voting</b>\n",
    "\n",
    "Predictions:\n",
    "\n",
    "    Classifier 1 predicts class A\n",
    "\n",
    "    Classifier 2 predicts class B\n",
    "\n",
    "    Classifier 3 predicts class B\n",
    "\n",
    "2/3 classifiers predict class B, so class B is the ensemble decision.\n",
    "\n",
    "<b>Soft voting</b>\n",
    "\n",
    "    Classifier 1 predicts class A with probability 99%\n",
    "\n",
    "    Classifier 2 predicts class A with probability 49%\n",
    "\n",
    "    Classifier 3 predicts class A with probability 49%\n",
    "\n",
    "The average probability of belonging to class A across the classifiers is (99 + 49 + 49) / 3 = 65.67%. Therefore, class A is the ensemble decision.\n",
    "\n",
    "Soft and Hard voting can lead to different decisions. Soft voting can improve on hard voting because it takes into account more information; it uses each classifier's uncertainty in the final decision. The high uncertainty in classifiers 2 and 3 here essentially meant that the final ensemble decision relied strongly on classifier 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process to choose the models to ensemble:\n",
    "\n",
    "> 1) First I selected all the models and formed an ensemble.\n",
    "\n",
    "> 2) I dropped the weak learners and then performed ensemble again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "named_estimators = [\n",
    "    (\"random_forest_clf\", random_forest_clf),\n",
    "    (\"extra_trees_clf\", extra_trees_clf),\n",
    "    (\"svm_clf\", svm_clf),\n",
    "    (\"mlp_clf\", mlp_clf),\n",
    "    (\"logistic_clf\", logisticRegr)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(named_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the Ensemble Classifier with the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "   ...enalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validating the Ensemble Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9633"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get accuracy about 96.33% which is lower than MLPClassifier. Below are the validation accuracies of individual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9606, 0.9646, 0.913, 0.9783, 0.9157]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_val, y_val) for estimator in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the ensemble model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9615"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We get accuracy about 96.15% which is lower than MLPClassifier. Below are the validation accuracies of individual model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9594, 0.9585, 0.9145, 0.9765, 0.917]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_test, y_test) for estimator in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the SVM and Logistic Classifiers because the accuracy is getting hurt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "   ...l=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)), ('logistic_clf', None)],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.set_params(logistic_clf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "   ...l=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)), ('logistic_clf', None)],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.set_params(svm_clf=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updated list of estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('random_forest_clf',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "              oob_score=False, random_state=42, verbose=0, warm_start=False)),\n",
       " ('extra_trees_clf',\n",
       "  ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "             oob_score=False, random_state=42, verbose=0, warm_start=False)),\n",
       " ('svm_clf', None),\n",
       " ('mlp_clf',\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "         beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "         hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "         learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "         nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
       "         solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "         warm_start=False)),\n",
       " ('logistic_clf', None)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "             oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       " LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "      verbose=0),\n",
       " MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
       "        solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "        warm_start=False),\n",
       " LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "           verbose=0, warm_start=False)]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, it did not update the list of trained estimators. So, we delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del voting_clf.estimators_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del voting_clf.estimators_[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on three classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9747"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "voting_clf.voting = \"soft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9808"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9794"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9594, 0.9585, 0.9765]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_test, y_test) for estimator in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above accuracies we see that ensemble classifier outperforms all the remaining classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can it be further improved:\n",
    "Given the limited time constraint, if even more time was given I could improve the accuracy to even 99.9%. I think the model can be further improved by making the following changes:\n",
    "\n",
    "> 1)Data Augmentation.\n",
    "\n",
    "> 2)Using Deep Learning instead of Traditional Machine Learning algorithms as shown the next section of this homework.\n",
    "\n",
    "> 3)Using CNN & Transfer Learning.\n",
    "\n",
    "> 4)Ensembling traditional Machine Learning and Deep Learning techniques to give even better accuracy.\n",
    "\n",
    "> 5)Using Capsule Networks for Classification which overcomes the limitations of CNN (spatial orientation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 99.7% algorithm (CNN & Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#used to help some of the timing functions\n",
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set some parameters\n",
    "batch_size = 128\n",
    "num_classes = 5\n",
    "epochs = 10\n",
    "img_rows, img_cols = 28, 28\n",
    "filters = 32\n",
    "pool_size = 2\n",
    "kernel_size = 3\n",
    "\n",
    "## This just handles some variability in how the input data is loaded\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Helper function to include all the training steps\n",
    "\n",
    "def train_model(model, train, test, num_classes):\n",
    "    \n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # converting class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    t = now()\n",
    "    # fitting the model\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    print('Training time: %s' % (now() - t))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# creating two datasets: one with digits below 5 and one with 5 and above\n",
    "x_train_lt5 = x_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "x_test_lt5 = x_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "x_train_gte5 = x_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5\n",
    "x_test_gte5 = x_test[y_test >= 5]\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# These are the early layers that we expect will \"transfer\"\n",
    "# They will be frozen during the fine-tuning process\n",
    "\n",
    "feature_layers = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# These are the later layers that predict the specific classes from the features\n",
    "# This is the part of the model that needs to be retrained for a new problem\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combining the two sets of layers\n",
    "model = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 600,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n",
      "Train on 29404 samples, validate on 4861 samples\n",
      "Epoch 1/10\n",
      "29404/29404 [==============================] - 79s 3ms/step - loss: 0.2289 - acc: 0.9211 - val_loss: 0.0580 - val_acc: 0.9815\n",
      "Epoch 2/10\n",
      "29404/29404 [==============================] - 79s 3ms/step - loss: 0.0697 - acc: 0.9784 - val_loss: 0.0424 - val_acc: 0.9856\n",
      "Epoch 3/10\n",
      "29404/29404 [==============================] - 77s 3ms/step - loss: 0.0494 - acc: 0.9847 - val_loss: 0.0309 - val_acc: 0.9889\n",
      "Epoch 4/10\n",
      "29404/29404 [==============================] - 76s 3ms/step - loss: 0.0394 - acc: 0.9880 - val_loss: 0.0243 - val_acc: 0.9912\n",
      "Epoch 5/10\n",
      "29404/29404 [==============================] - 77s 3ms/step - loss: 0.0348 - acc: 0.9887 - val_loss: 0.0228 - val_acc: 0.9922\n",
      "Epoch 6/10\n",
      "29404/29404 [==============================] - 78s 3ms/step - loss: 0.0285 - acc: 0.9908 - val_loss: 0.0229 - val_acc: 0.9920\n",
      "Epoch 7/10\n",
      "29404/29404 [==============================] - 78s 3ms/step - loss: 0.0244 - acc: 0.9917 - val_loss: 0.0224 - val_acc: 0.9920\n",
      "Epoch 8/10\n",
      "29404/29404 [==============================] - 80s 3ms/step - loss: 0.0234 - acc: 0.9925 - val_loss: 0.0198 - val_acc: 0.9926\n",
      "Epoch 9/10\n",
      "29404/29404 [==============================] - 79s 3ms/step - loss: 0.0194 - acc: 0.9941 - val_loss: 0.0209 - val_acc: 0.9909\n",
      "Epoch 10/10\n",
      "29404/29404 [==============================] - 80s 3ms/step - loss: 0.0189 - acc: 0.9937 - val_loss: 0.0209 - val_acc: 0.9926\n",
      "Training time: 0:13:02.578352\n",
      "Test score: 0.020935694306417334\n",
      "Test accuracy: 0.9925941163265909\n"
     ]
    }
   ],
   "source": [
    "# Training model on the digits 5,6,7,8,9\n",
    "\n",
    "train_model(model,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Freezing only the feature layers\n",
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After freezing the layers, We see the number of trainable parameters are 590597."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 590,597\n",
      "Non-trainable params: 9,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n",
      "Train on 30596 samples, validate on 5139 samples\n",
      "Epoch 1/10\n",
      "30596/30596 [==============================] - 39s 1ms/step - loss: 0.1805 - acc: 0.9525 - val_loss: 0.0175 - val_acc: 0.9944\n",
      "Epoch 2/10\n",
      "30596/30596 [==============================] - 39s 1ms/step - loss: 0.0430 - acc: 0.9870 - val_loss: 0.0123 - val_acc: 0.9959\n",
      "Epoch 3/10\n",
      "30596/30596 [==============================] - 39s 1ms/step - loss: 0.0303 - acc: 0.9903 - val_loss: 0.0083 - val_acc: 0.9969\n",
      "Epoch 4/10\n",
      "30596/30596 [==============================] - 39s 1ms/step - loss: 0.0248 - acc: 0.9931 - val_loss: 0.0080 - val_acc: 0.9975\n",
      "Epoch 5/10\n",
      "30596/30596 [==============================] - 40s 1ms/step - loss: 0.0188 - acc: 0.9942 - val_loss: 0.0059 - val_acc: 0.9982\n",
      "Epoch 6/10\n",
      "30596/30596 [==============================] - 39s 1ms/step - loss: 0.0186 - acc: 0.9942 - val_loss: 0.0061 - val_acc: 0.9975\n",
      "Epoch 7/10\n",
      "30596/30596 [==============================] - 40s 1ms/step - loss: 0.0177 - acc: 0.9948 - val_loss: 0.0057 - val_acc: 0.9981\n",
      "Epoch 8/10\n",
      "30596/30596 [==============================] - 39s 1ms/step - loss: 0.0143 - acc: 0.9955 - val_loss: 0.0058 - val_acc: 0.9977\n",
      "Epoch 9/10\n",
      "30596/30596 [==============================] - 39s 1ms/step - loss: 0.0133 - acc: 0.9959 - val_loss: 0.0052 - val_acc: 0.9979\n",
      "Epoch 10/10\n",
      "30596/30596 [==============================] - 40s 1ms/step - loss: 0.0109 - acc: 0.9964 - val_loss: 0.0050 - val_acc: 0.9984\n",
      "Training time: 0:06:33.689149\n",
      "Test score: 0.004965044073746302\n",
      "Test accuracy: 0.9984432769021211\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "train_model(model,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After a single epoch, I'm already achieving results on classifying 0-4 that are comparable to those achieved on 5-9 after 5 full epochs. This despite the fact the we are only \"fine-tuning\" the last layer of the network, and all the early layers have never seen what the digits 0-4 look like. he training time per epoch was still much reduced, this is because the unfrozen part of the network was very shallow, making backpropagation faster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
